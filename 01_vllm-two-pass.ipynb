{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963391b1-66dd-431f-b43d-a0bb86fc7ee1",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook can process many PDFs in parallel (with two-pass \"Deep Parsing\" to generate image descriptions). Upload PDFs in bulk to the pdfs directory and run the cells. The setup notebook needs to have been run first to prep the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926cd553-e756-41c0-89fa-64defca85936",
   "metadata": {},
   "source": [
    "# Cell 0 Unload GPU (Optional)\n",
    "- Used between runs to free GPU VRAM if needed/wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f816dd-d6e4-414b-97df-0ba6527b5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Clear GPU Memory\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLEARING GPU MEMORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Delete model if it exists\n",
    "if 'llm' in globals():\n",
    "    print(\"âœ“ Unloading model...\")\n",
    "    del llm\n",
    "\n",
    "# Delete any other large objects that might be in memory\n",
    "vars_to_clear = ['processor', 'pass2_processor', 'outputs', 'batch_inputs', \n",
    "                 'images', 'original_images', 'figure_descriptions']\n",
    "for var_name in vars_to_clear:\n",
    "    if var_name in globals():\n",
    "        print(f\"âœ“ Clearing {var_name}...\")\n",
    "        del globals()[var_name]\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Clear CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force synchronize to ensure cleanup is complete\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# Show results\n",
    "print(f\"\\nGPU Memory Status:\")\n",
    "print(f\"  Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "print(f\"  Reserved: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
    "print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1024**3:.2f} GB\")\n",
    "\n",
    "print(\"\\nâœ“ GPU memory cleared - ready for clean run\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a802f6-58cd-4211-825d-85b3036c6ec6",
   "metadata": {},
   "source": [
    "# Cell 1: Validate Environment\n",
    "- Confirm everything is installed and directories are in place as expected\n",
    "- Typically run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586cbbf4-a3a3-4114-997c-3d5fcc08a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Validate Environment\n",
    "import torch\n",
    "import vllm\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VALIDATING ENVIRONMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify versions\n",
    "print(f\"\\nvLLM version: {vllm.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "assert vllm.__version__ == \"0.8.5\", \"Wrong vLLM version! Run setup notebook.\"\n",
    "\n",
    "# Setup paths\n",
    "MODEL_PATH = \"/workspace/model/DeepSeek-OCR\"\n",
    "PDF_INPUT_DIR = \"/workspace/pdfs\"\n",
    "TEMP_DIR = \"/workspace/temp\"\n",
    "TEMP_PAGES_DIR = \"/workspace/temp/pages\"\n",
    "TEMP_FIGURES_DIR = \"/workspace/temp/figures\"\n",
    "TEMP_PASS1_RAW_DIR = \"/workspace/temp/pass1_raw\"\n",
    "OUTPUT_DIR = \"/workspace/output\"\n",
    "REPORTS_DIR = \"/workspace/reports\"\n",
    "\n",
    "# Create all directories\n",
    "for dir_path in [TEMP_DIR, TEMP_PAGES_DIR, TEMP_FIGURES_DIR, \n",
    "                 TEMP_PASS1_RAW_DIR, OUTPUT_DIR, REPORTS_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"\\nDirectories:\")\n",
    "print(f\"  Model: {MODEL_PATH}\")\n",
    "print(f\"  PDFs: {PDF_INPUT_DIR}\")\n",
    "print(f\"  Temp (pages): {TEMP_PAGES_DIR}\")\n",
    "print(f\"  Temp (figures): {TEMP_FIGURES_DIR}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Reports: {REPORTS_DIR}\")\n",
    "print(\"\\nâœ“ Environment Validated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592c26d-6bdc-48ab-b67b-508fa0915773",
   "metadata": {},
   "source": [
    "# Cell 2: Cleanup Temp Directories\n",
    "- Remove any leftover files from previous runs\n",
    "- Pages directory holds images of pages from PDFs, figures directory holds figures that have been extracted from pages, PASS1_RAW_DIR holds raw markdown output after pass 1 (including markdown tags and image coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e57ff-3ba0-4e6c-b639-c515323d3aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Cleanup Temp Directories\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLEANING TEMP DIRECTORIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "temp_dirs = [TEMP_PAGES_DIR, TEMP_FIGURES_DIR, TEMP_PASS1_RAW_DIR]\n",
    "\n",
    "for temp_dir in temp_dirs:\n",
    "    if Path(temp_dir).exists():\n",
    "        file_count = len(list(Path(temp_dir).glob(\"*\")))\n",
    "        shutil.rmtree(temp_dir)\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "        print(f\"âœ“ Cleaned {temp_dir}\")\n",
    "        print(f\"  Removed {file_count} files\")\n",
    "    else:\n",
    "        print(f\"âš  {temp_dir} doesn't exist\")\n",
    "\n",
    "print(\"\\nâœ“ All temp directories cleaned and ready for next run\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa342bec-3c70-4b9f-b231-0fe348baa070",
   "metadata": {},
   "source": [
    "# Cell 3a: Pass 1 Configuration\n",
    "- Pass 1 converts a PDF to markdown but does not produce images - it only identifies their locations.\n",
    "- Override config.py (in the cloned repo) to provide control over key settings here in the notebook. Adjust NUM_WORKERS to control parallelization of CPU operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979353fd-0504-4b91-89a0-d7535ded50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3a: Configuration - Pass 1\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION - PASS 1\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Add DeepSeek repo to path\n",
    "repo_path = '/workspace/DeepSeek-OCR-repo'\n",
    "vllm_impl_path = os.path.join(repo_path, 'DeepSeek-OCR-master', 'DeepSeek-OCR-vllm')\n",
    "\n",
    "if not os.path.exists(repo_path):\n",
    "    print(\"\\nâš  Repository not found, cloning...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/deepseek-ai/DeepSeek-OCR.git', repo_path], \n",
    "                   check=True, capture_output=True)\n",
    "    print(\"âœ“ Repository cloned\")\n",
    "\n",
    "if vllm_impl_path not in sys.path:\n",
    "    sys.path.insert(0, vllm_impl_path)\n",
    "\n",
    "# Import config module (but don't import processor yet!)\n",
    "import config\n",
    "\n",
    "# CPU Configuration\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "logical_cores = psutil.cpu_count(logical=True)\n",
    "\n",
    "cpu_model = subprocess.run(\n",
    "    [\"grep\", \"-m\", \"1\", \"model name\", \"/proc/cpuinfo\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ").stdout.strip().split(':')[1].strip()\n",
    "\n",
    "print(f\"\\nCPU Info:\")\n",
    "print(f\"  Model: {cpu_model}\")\n",
    "print(f\"  Physical Cores: {physical_cores}\")\n",
    "print(f\"  Logical Cores: {logical_cores}\")\n",
    "\n",
    "# ============================================================\n",
    "# PASS 1 SETTINGS - USER CONFIGURABLE\n",
    "# ============================================================\n",
    "\n",
    "# PDF to Image Conversion\n",
    "PDF_DPI = 144  # DPI for PDF page images (higher = better quality, larger files)\n",
    "\n",
    "# Image Processing Settings\n",
    "BASE_SIZE = 1024\n",
    "IMAGE_SIZE = 640\n",
    "CROP_MODE = True\n",
    "MIN_CROPS = 2\n",
    "MAX_CROPS = 6\n",
    "NUM_WORKERS = 32 # physical_cores  # CPU preprocessing threads\n",
    "\n",
    "# GPU Model Settings\n",
    "PASS1_MAX_MODEL_LEN = 8192\n",
    "PASS1_MAX_NUM_SEQS = 100  # Batch size / controls number of images processed in parallel\n",
    "PASS1_GPU_MEMORY_UTIL = 0.95\n",
    "\n",
    "# Generation Settings\n",
    "PASS1_TEMPERATURE = 0.0\n",
    "PASS1_MAX_TOKENS = 8192\n",
    "\n",
    "# Prompt\n",
    "PASS1_PROMPT = '<image>\\n<|grounding|>Convert the document to markdown.'\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "# Override config.py with our settings\n",
    "config.BASE_SIZE = BASE_SIZE\n",
    "config.IMAGE_SIZE = IMAGE_SIZE\n",
    "config.CROP_MODE = CROP_MODE\n",
    "config.MIN_CROPS = MIN_CROPS\n",
    "config.MAX_CROPS = MAX_CROPS\n",
    "config.NUM_WORKERS = NUM_WORKERS\n",
    "config.MAX_CONCURRENCY = PASS1_MAX_NUM_SEQS\n",
    "config.MODEL_PATH = MODEL_PATH\n",
    "config.PROMPT = PASS1_PROMPT\n",
    "\n",
    "print(f\"\\nâœ“ Configuration Override Applied\")\n",
    "print(f\"  BASE_SIZE: {BASE_SIZE}\")\n",
    "print(f\"  IMAGE_SIZE: {IMAGE_SIZE}\")\n",
    "print(f\"  CROP_MODE: {CROP_MODE}\")\n",
    "print(f\"  MIN_CROPS: {MIN_CROPS}\")\n",
    "print(f\"  MAX_CROPS: {MAX_CROPS}\")\n",
    "print(f\"  Expected tokens per image: 64\")\n",
    "\n",
    "print(f\"\\nCPU Preprocessing:\")\n",
    "print(f\"  NUM_WORKERS: {NUM_WORKERS}\")\n",
    "print(f\"  ðŸ’¡ Recommended range: {int(physical_cores * 1.5)}-{physical_cores * 2}\")\n",
    "\n",
    "print(f\"\\nGPU Model Settings:\")\n",
    "print(f\"  max_model_len: {PASS1_MAX_MODEL_LEN}\")\n",
    "print(f\"  max_num_seqs (batch size): {PASS1_MAX_NUM_SEQS}\")\n",
    "print(f\"  gpu_memory_utilization: {PASS1_GPU_MEMORY_UTIL}\")\n",
    "\n",
    "print(f\"\\nGeneration Settings:\")\n",
    "print(f\"  temperature: {PASS1_TEMPERATURE}\")\n",
    "print(f\"  max_tokens: {PASS1_MAX_TOKENS}\")\n",
    "\n",
    "print(f\"\\nPrompt:\")\n",
    "print(f\"  {PASS1_PROMPT}\")\n",
    "\n",
    "print(\"\\nâœ“ Configuration complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5286f3-6316-4229-b999-9d8be799873b",
   "metadata": {},
   "source": [
    "# Cell 3b: Pass 2 Configuration\n",
    "- Pass 2 uses image locations identified in pass 1, extracts and saves the images, then runs the images through the model with a different prompt to produce image descriptions\n",
    "- This cell (like 3a) also overrides config.py (in the cloned repo) to provide control over key settings here in the notebook. Pay attention to CPU NUM_WORKERS.\n",
    "- Higher batch size (200 vs 100) - cropped figures are smaller, can fit more in VRAM\n",
    "- Higher temperature (0.2 vs 0.0) - encourages more natural descriptions\n",
    "- Fewer max_tokens (2048 vs 8192) - descriptions are shorter than full-page OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f9107-fecf-4b06-b985-c8dd9419831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3b: Configuration - Pass 2\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION - PASS 2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# PASS 2 SETTINGS - USER CONFIGURABLE\n",
    "# ============================================================\n",
    "\n",
    "# Image Processing Settings (reuse from Pass 1, or customize)\n",
    "PASS2_BASE_SIZE = 1024  # Can be same or different from Pass 1\n",
    "PASS2_IMAGE_SIZE = 640\n",
    "PASS2_CROP_MODE = True\n",
    "PASS2_MIN_CROPS = 2\n",
    "PASS2_MAX_CROPS = 6\n",
    "PASS2_NUM_WORKERS = 32 # physical_cores  # CPU preprocessing threads\n",
    "\n",
    "# GPU Model Settings\n",
    "PASS2_MAX_MODEL_LEN = 8192\n",
    "PASS2_MAX_NUM_SEQS = 200  # Higher than Pass 1 - cropped figures are smaller!\n",
    "PASS2_GPU_MEMORY_UTIL = 0.95\n",
    "\n",
    "# Generation Settings\n",
    "PASS2_TEMPERATURE = 0.2  # Slightly higher for more natural descriptions\n",
    "PASS2_MAX_TOKENS = 2048  # Descriptions are shorter than full page OCR\n",
    "\n",
    "# Prompt\n",
    "PASS2_PROMPT = '<image>\\nDescribe this image in detail'\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nâœ“ Pass 2 Configuration Set\")\n",
    "\n",
    "print(f\"\\nImage Processing:\")\n",
    "print(f\"  BASE_SIZE: {PASS2_BASE_SIZE}\")\n",
    "print(f\"  IMAGE_SIZE: {PASS2_IMAGE_SIZE}\")\n",
    "print(f\"  CROP_MODE: {PASS2_CROP_MODE}\")\n",
    "print(f\"  NUM_WORKERS: {PASS2_NUM_WORKERS}\")\n",
    "\n",
    "print(f\"\\nGPU Model Settings:\")\n",
    "print(f\"  max_model_len: {PASS2_MAX_MODEL_LEN}\")\n",
    "print(f\"  max_num_seqs (batch size): {PASS2_MAX_NUM_SEQS}\")\n",
    "print(f\"  ðŸ’¡ Increased from Pass 1 ({PASS1_MAX_NUM_SEQS}) - figures are smaller\")\n",
    "print(f\"  gpu_memory_utilization: {PASS2_GPU_MEMORY_UTIL}\")\n",
    "\n",
    "print(f\"\\nGeneration Settings:\")\n",
    "print(f\"  temperature: {PASS2_TEMPERATURE} (higher for natural language)\")\n",
    "print(f\"  max_tokens: {PASS2_MAX_TOKENS} (shorter than Pass 1)\")\n",
    "\n",
    "print(f\"\\nPrompt:\")\n",
    "print(f\"  {PASS2_PROMPT}\")\n",
    "\n",
    "print(\"\\nâœ“ Pass 2 configuration complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f631c-0561-48c4-8f04-b3ce6d51ef0a",
   "metadata": {},
   "source": [
    "# Cell 4: PDF Inventory\n",
    "- This cell determines the number of pdfs in the `pdfs` directory, the file size for the job, and creates a list of files to be pre-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cea2d1-3a66-4d9d-9b7d-d34d54db49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: PDF Inventory\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_files = sorted(Path(PDF_INPUT_DIR).glob(\"*.pdf\"))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PDF INVENTORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if len(pdf_files) == 0:\n",
    "    raise FileNotFoundError(f\"No PDFs found in {PDF_INPUT_DIR}\")\n",
    "\n",
    "total_size_mb = sum(f.stat().st_size for f in pdf_files) / (1024**2)\n",
    "total_size_gb = total_size_mb / 1024\n",
    "\n",
    "print(f\"\\nFound {len(pdf_files)} PDF(s)\")\n",
    "print(f\"Total size: {total_size_mb:.2f} MB ({total_size_gb:.3f} GB)\")\n",
    "print(f\"\\nFiles:\")\n",
    "for pdf in pdf_files:\n",
    "    size_mb = pdf.stat().st_size / (1024**2)\n",
    "    print(f\"  - {pdf.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\nâœ“ Ready for preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021764c-85f5-4723-8625-da407f96fd90",
   "metadata": {},
   "source": [
    "# Cell 5: Load Model for Pass 1\n",
    "- This cell loads DeepseekOCRForCausalLM which is actually the entire pipeline in one unified model object\n",
    "- This includes:\n",
    "    - DeepEncoder (Vision Processing)\n",
    "        - SAM (Segment Anything Model) - 80M params\n",
    "        - 16Ã— Convolutional Compressor\n",
    "        - CLIP-large - 300M params\n",
    "    - DeepSeek-3B-MoE (Language Decoder)\n",
    "        - Mixture of Experts decoder - generates text\n",
    "- This is all contained in `deepseek_ocr.py` in the GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59dded-4040-452b-b9f0-e640112f0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load Model\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear any existing model from memory\n",
    "if 'llm' in globals():\n",
    "    del llm\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "os.environ['VLLM_USE_V1'] = '0'\n",
    "\n",
    "# Import and register (repo already in path from Cell 2)\n",
    "from deepseek_ocr import DeepseekOCRForCausalLM\n",
    "from vllm.model_executor.models.registry import ModelRegistry\n",
    "from vllm import LLM, SamplingParams\n",
    "from process.ngram_norepeat import NoRepeatNGramLogitsProcessor\n",
    "\n",
    "ModelRegistry.register_model(\"DeepseekOCRForCausalLM\", DeepseekOCRForCausalLM)\n",
    "\n",
    "print(f\"\\nGPU Memory Before Load: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "llm = LLM(\n",
    "    model=MODEL_PATH,\n",
    "    hf_overrides={\"architectures\": [\"DeepseekOCRForCausalLM\"]},\n",
    "    block_size=256,\n",
    "    enforce_eager=False,\n",
    "    trust_remote_code=True, \n",
    "    max_model_len=PASS1_MAX_MODEL_LEN,\n",
    "    swap_space=0,\n",
    "    max_num_seqs=PASS1_MAX_NUM_SEQS,\n",
    "    tensor_parallel_size=1,\n",
    "    gpu_memory_utilization=PASS1_GPU_MEMORY_UTIL,\n",
    "    disable_mm_preprocessor_cache=True\n",
    ")\n",
    "\n",
    "print(f\"GPU Memory After Load: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
    "\n",
    "# Setup sampling parameters for Pass 1\n",
    "logits_processors = [NoRepeatNGramLogitsProcessor(\n",
    "    ngram_size=20, window_size=50, whitelist_token_ids={128821, 128822}\n",
    ")]\n",
    "\n",
    "sampling_params_pass1 = SamplingParams(\n",
    "    temperature=PASS1_TEMPERATURE,\n",
    "    max_tokens=PASS1_MAX_TOKENS,\n",
    "    logits_processors=logits_processors,\n",
    "    skip_special_tokens=False,\n",
    "    include_stop_str_in_output=True,\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Model loaded and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893b274-d095-491b-8ed6-438bb40888b7",
   "metadata": {},
   "source": [
    "# Cell 6a: Pass 1 CPU Preprocessing - Convert All PDFs to Images for Each Page\n",
    "- The DeepSeek pipeline uses CPU to pre-process the PDFs by converting each page to an image\n",
    "- Overall job timing starts in this cell\n",
    "- This cell parallelizes PDF pages across NUM_WORKERS. You can adjust this in an earlier cell based on your hardware\n",
    "- Saves PNG images of each page to temp/pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584e96e-57be-4040-821e-97afba120887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6a: CPU Preprocessing - Convert All PDFs to Page Images (Parallelized)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import time\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import io as io_module\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def convert_single_page(pdf_path, page_num, dpi=None):\n",
    "    \"\"\"Convert a single page to an image and save it\"\"\"\n",
    "    if dpi is None:\n",
    "        dpi = PDF_DPI  # Use config value\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        zoom = dpi / 72.0\n",
    "        matrix = fitz.Matrix(zoom, zoom)\n",
    "        \n",
    "        page = pdf_document[page_num]\n",
    "        pixmap = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "        img_data = pixmap.tobytes(\"png\")\n",
    "        img = Image.open(io_module.BytesIO(img_data))\n",
    "        \n",
    "        # Save immediately\n",
    "        pdf_stem = Path(pdf_path).stem\n",
    "        img_filename = f\"{pdf_stem}_page{page_num+1:04d}.png\"\n",
    "        img_path = Path(TEMP_PAGES_DIR) / img_filename\n",
    "        img.save(img_path)\n",
    "        \n",
    "        pdf_document.close()\n",
    "        return (pdf_path, page_num, True, img_filename)\n",
    "    except Exception as e:\n",
    "        return (pdf_path, page_num, False, str(e))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CPU PREPROCESSING: PDF â†’ PAGE IMAGES (PARALLELIZED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize timing tracker\n",
    "timing_data = {}\n",
    "pipeline_start = time.time()\n",
    "\n",
    "# Clear temp/pages directory\n",
    "if os.path.exists(TEMP_PAGES_DIR):\n",
    "    shutil.rmtree(TEMP_PAGES_DIR)\n",
    "os.makedirs(TEMP_PAGES_DIR, exist_ok=True)\n",
    "\n",
    "preprocessing_start = time.time()\n",
    "\n",
    "# Build list of all pages to process\n",
    "page_jobs = []\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        pdf_document = fitz.open(str(pdf_path))\n",
    "        num_pages = pdf_document.page_count\n",
    "        pdf_document.close()\n",
    "        \n",
    "        for page_num in range(num_pages):\n",
    "            page_jobs.append((str(pdf_path), page_num))\n",
    "        \n",
    "        print(f\"Queued: {pdf_path.name} ({num_pages} pages)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Failed to open {pdf_path.name}: {e}\")\n",
    "\n",
    "total_pages = len(page_jobs)\n",
    "print(f\"\\nTotal pages to process: {total_pages}\")\n",
    "print(f\"Using {NUM_WORKERS} worker threads\\n\")\n",
    "\n",
    "# Process all pages in parallel\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = {\n",
    "        executor.submit(convert_single_page, pdf_path, page_num): (pdf_path, page_num)\n",
    "        for pdf_path, page_num in page_jobs\n",
    "    }\n",
    "    \n",
    "    # Process as they complete\n",
    "    for future in as_completed(futures):\n",
    "        pdf_path, page_num, success, result = future.result()\n",
    "        if success:\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "            print(f\"âœ— Failed: {Path(pdf_path).name} page {page_num+1}: {result}\")\n",
    "        \n",
    "        # Progress indicator every 100 pages\n",
    "        if (successful + failed) % 100 == 0:\n",
    "            print(f\"  Progress: {successful + failed}/{total_pages} pages processed...\")\n",
    "\n",
    "preprocessing_time = time.time() - preprocessing_start\n",
    "pages_per_sec = successful / preprocessing_time if preprocessing_time > 0 else 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ“ Preprocessing Complete\")\n",
    "print(f\"  Total Pages: {total_pages}\")\n",
    "print(f\"  Successful: {successful}\")\n",
    "print(f\"  Failed: {failed}\")\n",
    "print(f\"  Time: {preprocessing_time:.2f}s ({pages_per_sec:.2f} pages/sec)\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "print(f\"  Images saved to: {TEMP_PAGES_DIR}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['pdf_to_images'] = preprocessing_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4089616-5be5-4261-8088-1f82fe946935",
   "metadata": {},
   "source": [
    "# Cell 6b: Pass 1 CPU Preprocessing - Apply \"DeepSeek Preprocessing\"\n",
    "- The DeepSeek pipeline uses CPU to resize, crop, tile, and tokenize the page images (depending on resolution mode) prior to GPU processing.\n",
    "- This cell parallelizes PDF pages across NUM_WORKERS. You can adjust this in an earlier cell based on your hardware\n",
    "- This creates `batch_inputs` which contains the prompt and tensors representing each page (list of dictionaries) and is stored in RAM for fast transfer into the GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ad591-912f-4791-8268-bff221b826f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6b: CPU Preprocessing - Apply DeepSeek Image Processing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CPU PREPROCESSING: DEEPSEEK IMAGE PROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CRITICAL: Force reload config to Pass 1 settings before creating processor to avoid accidental use of Pass 2 settings\n",
    "print(\"\\n[Config] Forcing Pass 1 configuration reload...\")\n",
    "config_module = sys.modules['config']\n",
    "config_module.PROMPT = PASS1_PROMPT\n",
    "config_module.BASE_SIZE = BASE_SIZE\n",
    "config_module.IMAGE_SIZE = IMAGE_SIZE\n",
    "config_module.CROP_MODE = CROP_MODE\n",
    "config_module.NUM_WORKERS = NUM_WORKERS\n",
    "\n",
    "# Reload image_process module to pick up Pass 1 config\n",
    "if 'process.image_process' in sys.modules:\n",
    "    import process.image_process\n",
    "    importlib.reload(process.image_process)\n",
    "\n",
    "from process.image_process import DeepseekOCRProcessor\n",
    "\n",
    "# Create NEW processor instance with Pass 1 settings\n",
    "processor = DeepseekOCRProcessor()\n",
    "\n",
    "print(f\"âœ“ Processor created with Pass 1 configuration\")\n",
    "print(f\"  BASE_SIZE: {config_module.BASE_SIZE}\")\n",
    "print(f\"  IMAGE_SIZE: {config_module.IMAGE_SIZE}\")\n",
    "print(f\"  CROP_MODE: {config_module.CROP_MODE}\")\n",
    "print(f\"  NUM_WORKERS: {config_module.NUM_WORKERS}\")\n",
    "print(f\"  PROMPT: {config_module.PROMPT}\")\n",
    "\n",
    "def process_single_page_image(img_path):\n",
    "    \"\"\"Apply DeepSeek preprocessing to a single page image\"\"\"\n",
    "    try:\n",
    "        # Load image\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Apply DeepSeek preprocessing (resize, crop, tile, tokenize)\n",
    "        processed = processor.tokenize_with_images(\n",
    "            images=[image], \n",
    "            bos=True, \n",
    "            eos=True, \n",
    "            cropping=config.CROP_MODE\n",
    "        )\n",
    "        \n",
    "        return (img_path.name, True, processed)\n",
    "    except Exception as e:\n",
    "        return (img_path.name, False, str(e))\n",
    "\n",
    "# Get all page images from temp/pages/ in SORTED order\n",
    "page_image_files = sorted(Path(TEMP_PAGES_DIR).glob(\"*.png\"))\n",
    "total_images = len(page_image_files)\n",
    "\n",
    "print(f\"\\nFound {total_images} page images to preprocess\")\n",
    "print(f\"Using {NUM_WORKERS} worker threads\\n\")\n",
    "\n",
    "preprocess_start = time.time()\n",
    "\n",
    "# Store results with filenames for later sorting\n",
    "results = []\n",
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = {\n",
    "        executor.submit(process_single_page_image, img_path): img_path\n",
    "        for img_path in page_image_files\n",
    "    }\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(futures):\n",
    "        img_name, success, result = future.result()\n",
    "        \n",
    "        if success:\n",
    "            results.append((img_name, result))  # Store filename with result\n",
    "            successful += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "            print(f\"âœ— Failed: {img_name}: {result}\")\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (successful + failed) % 100 == 0:\n",
    "            print(f\"  Progress: {successful + failed}/{total_images} images processed...\")\n",
    "\n",
    "# CRITICAL: Sort results by filename to maintain order\n",
    "results.sort(key=lambda x: x[0])\n",
    "\n",
    "# Build batch_inputs in sorted order\n",
    "batch_inputs = []\n",
    "for img_name, processed in results:\n",
    "    batch_inputs.append({\n",
    "        \"prompt\": PASS1_PROMPT,\n",
    "        \"multi_modal_data\": {\"image\": processed},\n",
    "    })\n",
    "\n",
    "preprocess_time = time.time() - preprocess_start\n",
    "images_per_sec = successful / preprocess_time if preprocess_time > 0 else 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  Total Images: {total_images}\")\n",
    "print(f\"  Successful: {successful}\")\n",
    "print(f\"  Failed: {failed}\")\n",
    "print(f\"  Time: {preprocess_time:.2f}s ({images_per_sec:.2f} images/sec)\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "print(f\"  Batch inputs ready (SORTED): {len(batch_inputs)}\")\n",
    "print(f\"âœ“ DeepSeek Preprocessing Complete\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['deepseek_preprocessing_pass1'] = preprocess_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2f259-9d5f-4ef1-9fc3-6c4885246efb",
   "metadata": {},
   "source": [
    "# Cell 6c: Run Pass 1 on GPU\n",
    "- Clears temp/pass1_raw/ directory\n",
    "- Takes the batch_inputs from previous cell (already preprocessed)\n",
    "- Runs through GPU with llm.generate() (batched automatically by vLLM)\n",
    "- Saves each page's markdown output to temp/pass1_raw/ with matching filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab50862-9cbb-4776-bc4f-6898c296b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6c: GPU Processing - Pass 1 OCR\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU PROCESSING - PASS 1 OCR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ensure config is set to Pass 1 (in case Pass 2 was run previously)\n",
    "config.PROMPT = PASS1_PROMPT\n",
    "print(f\"âœ“ Config set to Pass 1 prompt\")\n",
    "\n",
    "# Clear pass1_raw directory\n",
    "if os.path.exists(TEMP_PASS1_RAW_DIR):\n",
    "    shutil.rmtree(TEMP_PASS1_RAW_DIR)\n",
    "os.makedirs(TEMP_PASS1_RAW_DIR, exist_ok=True)\n",
    "\n",
    "# Check that we have preprocessed batch_inputs from Cell 4b\n",
    "if 'batch_inputs' not in globals() or len(batch_inputs) == 0:\n",
    "    raise RuntimeError(\"No batch_inputs found! Run Cell 4b first.\")\n",
    "\n",
    "total_pages = len(batch_inputs)\n",
    "print(f\"\\nProcessing {total_pages} preprocessed page images\")\n",
    "print(f\"Batch size (max_num_seqs): {PASS1_MAX_NUM_SEQS}\")\n",
    "print(f\"GPU Memory Utilization: {PASS1_GPU_MEMORY_UTIL}\")\n",
    "\n",
    "# Run GPU inference\n",
    "gpu_start = time.time()\n",
    "\n",
    "outputs = llm.generate(batch_inputs, sampling_params=sampling_params_pass1)\n",
    "\n",
    "gpu_time = time.time() - gpu_start\n",
    "pages_per_sec = total_pages / gpu_time if gpu_time > 0 else 0\n",
    "\n",
    "print(f\"\\nâœ“ GPU Processing Complete\")\n",
    "print(f\"  Time: {gpu_time:.2f}s ({pages_per_sec:.2f} pages/sec)\")\n",
    "\n",
    "# Save outputs to temp/pass1_raw/\n",
    "print(f\"\\nSaving markdown outputs to {TEMP_PASS1_RAW_DIR}...\")\n",
    "\n",
    "# Get original filenames from temp/pages to maintain mapping\n",
    "page_image_files = sorted(Path(TEMP_PAGES_DIR).glob(\"*.png\"))\n",
    "\n",
    "for img_path, output in zip(page_image_files, outputs):\n",
    "    # Extract PDF name and page number from filename\n",
    "    # Format: {pdf_stem}_page{0001}.png\n",
    "    img_stem = img_path.stem  # e.g., \"document_page0001\"\n",
    "    \n",
    "    # Save markdown with same naming convention\n",
    "    markdown_filename = f\"{img_stem}.md\"\n",
    "    markdown_path = Path(TEMP_PASS1_RAW_DIR) / markdown_filename\n",
    "    \n",
    "    # Get generated text\n",
    "    markdown_text = output.outputs[0].text\n",
    "    \n",
    "    # Save to file\n",
    "    with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(markdown_text)\n",
    "\n",
    "print(f\"âœ“ Saved {len(outputs)} markdown files\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PASS 1 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Total Pages: {total_pages}\")\n",
    "print(f\"  GPU Time: {gpu_time:.2f}s\")\n",
    "print(f\"  Throughput: {pages_per_sec:.2f} pages/sec\")\n",
    "print(f\"  Output Location: {TEMP_PASS1_RAW_DIR}\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['gpu_inference_pass1'] = gpu_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebd6f5-308d-423a-841c-98e1ce2efea8",
   "metadata": {},
   "source": [
    "# Cell 7: Extract & Crop Figures from Pass 1 Output\n",
    "- Clears temp/figures/\n",
    "- Reads each markdown file from temp/pass1_raw/\n",
    "- Extracts normalized coordinates for images\n",
    "- Denormalizes to pixel coordinates\n",
    "- Crops from original page images in temp/pages/\n",
    "- Saves to temp/figures/ with naming: document_page0001_fig01.png\n",
    "- Uses NUM_WORKERS for parallel CPU processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd36dd1-62ec-4e69-92e2-54ec3c936601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Extract & Crop Figures from Pass 1 Output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING & CROPPING FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Clear temp/figures directory\n",
    "if os.path.exists(TEMP_FIGURES_DIR):\n",
    "    shutil.rmtree(TEMP_FIGURES_DIR)\n",
    "os.makedirs(TEMP_FIGURES_DIR, exist_ok=True)\n",
    "\n",
    "def extract_figure_coordinates(markdown_text):\n",
    "    \"\"\"\n",
    "    Extract ONLY image/figure references with valid bounding boxes.\n",
    "    Returns list of normalized coordinates (0-999 range).\n",
    "    \"\"\"\n",
    "    figures = []\n",
    "    lines = markdown_text.split('\\n')\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        # Skip image_caption tags\n",
    "        if 'image_caption' in line:\n",
    "            continue\n",
    "        \n",
    "        # Look for image tags with coordinates\n",
    "        if '<|ref|>image<|/ref|>' in line and '<|det|>' in line:\n",
    "            coord_match = re.search(r'<\\|det\\|>\\[\\[(\\d+),\\s*(\\d+),\\s*(\\d+),\\s*(\\d+)\\]\\]<\\|/det\\|>', line)\n",
    "            \n",
    "            if coord_match:\n",
    "                x1, y1, x2, y2 = map(int, coord_match.groups())\n",
    "                \n",
    "                # Validate in normalized space (0-999)\n",
    "                width = x2 - x1\n",
    "                height = y2 - y1\n",
    "                \n",
    "                # Filter out tiny/invalid boxes\n",
    "                if width > 50 and height > 50 and x1 < x2 and y1 < y2 and x2 <= 999 and y2 <= 999:\n",
    "                    figures.append({\n",
    "                        'bbox_normalized': (x1, y1, x2, y2),\n",
    "                        'line_number': i\n",
    "                    })\n",
    "    \n",
    "    return figures\n",
    "\n",
    "def denormalize_bbox(bbox_normalized, image_width, image_height):\n",
    "    \"\"\"Convert normalized bounding box (0-999) to pixel coordinates.\"\"\"\n",
    "    x1, y1, x2, y2 = bbox_normalized\n",
    "    \n",
    "    x1_pixel = int(x1 / 999 * image_width)\n",
    "    y1_pixel = int(y1 / 999 * image_height)\n",
    "    x2_pixel = int(x2 / 999 * image_width)\n",
    "    y2_pixel = int(y2 / 999 * image_height)\n",
    "    \n",
    "    return (x1_pixel, y1_pixel, x2_pixel, y2_pixel)\n",
    "\n",
    "def process_single_page(markdown_path):\n",
    "    \"\"\"Process one page: extract figures and crop from original image.\"\"\"\n",
    "    try:\n",
    "        # Read markdown\n",
    "        with open(markdown_path, 'r', encoding='utf-8') as f:\n",
    "            markdown_text = f.read()\n",
    "        \n",
    "        # Extract figure coordinates\n",
    "        figures = extract_figure_coordinates(markdown_text)\n",
    "        \n",
    "        if not figures:\n",
    "            return (markdown_path.stem, 0, True, \"No figures found\")\n",
    "        \n",
    "        # Find corresponding page image\n",
    "        page_stem = markdown_path.stem  # e.g., \"document_page0001\"\n",
    "        page_image_path = Path(TEMP_PAGES_DIR) / f\"{page_stem}.png\"\n",
    "        \n",
    "        if not page_image_path.exists():\n",
    "            return (markdown_path.stem, 0, False, f\"Page image not found: {page_image_path}\")\n",
    "        \n",
    "        # Load original page image\n",
    "        page_image = Image.open(page_image_path)\n",
    "        image_width, image_height = page_image.size\n",
    "        \n",
    "        # Crop each figure\n",
    "        figures_cropped = 0\n",
    "        for fig_idx, fig_info in enumerate(figures, 1):\n",
    "            bbox_normalized = fig_info['bbox_normalized']\n",
    "            bbox_pixel = denormalize_bbox(bbox_normalized, image_width, image_height)\n",
    "            \n",
    "            # Add padding and crop\n",
    "            x1, y1, x2, y2 = bbox_pixel\n",
    "            padding = 10\n",
    "            x1 = max(0, x1 - padding)\n",
    "            y1 = max(0, y1 - padding)\n",
    "            x2 = min(image_width, x2 + padding)\n",
    "            y2 = min(image_height, y2 + padding)\n",
    "            \n",
    "            cropped_figure = page_image.crop((x1, y1, x2, y2))\n",
    "            \n",
    "            # Save with naming convention: {page_stem}_fig{01}.png\n",
    "            fig_filename = f\"{page_stem}_fig{fig_idx:02d}.png\"\n",
    "            fig_path = Path(TEMP_FIGURES_DIR) / fig_filename\n",
    "            cropped_figure.save(fig_path)\n",
    "            \n",
    "            figures_cropped += 1\n",
    "        \n",
    "        return (markdown_path.stem, figures_cropped, True, None)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return (markdown_path.stem, 0, False, str(e))\n",
    "\n",
    "# Get all markdown files from pass1_raw\n",
    "markdown_files = sorted(Path(TEMP_PASS1_RAW_DIR).glob(\"*.md\"))\n",
    "total_pages = len(markdown_files)\n",
    "\n",
    "print(f\"\\nProcessing {total_pages} markdown files\")\n",
    "print(f\"Using {NUM_WORKERS} worker threads\\n\")\n",
    "\n",
    "extract_start = time.time()\n",
    "\n",
    "total_figures = 0\n",
    "successful_pages = 0\n",
    "failed_pages = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "    futures = {\n",
    "        executor.submit(process_single_page, md_path): md_path\n",
    "        for md_path in markdown_files\n",
    "    }\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        page_stem, num_figures, success, error = future.result()\n",
    "        \n",
    "        if success:\n",
    "            successful_pages += 1\n",
    "            total_figures += num_figures\n",
    "            if num_figures > 0:\n",
    "                print(f\"âœ“ {page_stem}: Extracted {num_figures} figure(s)\")\n",
    "        else:\n",
    "            failed_pages += 1\n",
    "            print(f\"âœ— {page_stem}: {error}\")\n",
    "\n",
    "extract_time = time.time() - extract_start\n",
    "figures_per_sec = total_figures / extract_time if extract_time > 0 else 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  Pages Processed: {successful_pages}/{total_pages}\")\n",
    "print(f\"  Total Figures Extracted: {total_figures}\")\n",
    "print(f\"  Time: {extract_time:.2f}s ({figures_per_sec:.2f} figures/sec)\")\n",
    "print(f\"  Workers: {NUM_WORKERS}\")\n",
    "print(f\"  Figures saved to: {TEMP_FIGURES_DIR}\")\n",
    "print(f\"âœ“ Figure Extraction Complete\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['figure_extraction'] = extract_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9310ee-c6eb-4ccd-8309-41fab98230cd",
   "metadata": {},
   "source": [
    "# Cell 8a: Pass 2 CPU Preprocessing - Prep Extracted Images\n",
    "- Reloads config module with Pass 2 settings\n",
    "- Reloads the image processor to pick up new config\n",
    "- Loads all extracted figures from temp/figures/\n",
    "- Applies DeepSeek preprocessing in parallel (using PASS2_NUM_WORKERS)\n",
    "- Sorts results by filename\n",
    "- Builds batch_inputs_pass2 (prompt and image tensors) ready for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb68fe9-f8b0-4eb1-b1ce-f6658c28e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8a: CPU Preprocessing - Pass 2 Figures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "from process.image_process import DeepseekOCRProcessor\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CPU PREPROCESSING: PASS 2 FIGURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Force config reload to use Pass 2 settings\n",
    "print(\"\\n[Config] Reloading config module with Pass 2 settings...\")\n",
    "config_module = sys.modules['config']\n",
    "\n",
    "# Override config with Pass 2 settings\n",
    "config_module.BASE_SIZE = PASS2_BASE_SIZE\n",
    "config_module.IMAGE_SIZE = PASS2_IMAGE_SIZE\n",
    "config_module.CROP_MODE = PASS2_CROP_MODE\n",
    "config_module.MIN_CROPS = PASS2_MIN_CROPS\n",
    "config_module.MAX_CROPS = PASS2_MAX_CROPS\n",
    "config_module.NUM_WORKERS = PASS2_NUM_WORKERS\n",
    "config_module.PROMPT = PASS2_PROMPT\n",
    "\n",
    "# Reload image_process module to pick up new config\n",
    "if 'process.image_process' in sys.modules:\n",
    "    import process.image_process\n",
    "    importlib.reload(process.image_process)\n",
    "\n",
    "from process.image_process import DeepseekOCRProcessor\n",
    "\n",
    "# Create new processor instance with Pass 2 settings\n",
    "processor_pass2 = DeepseekOCRProcessor()\n",
    "\n",
    "print(f\"âœ“ Processor reloaded with Pass 2 configuration\")\n",
    "print(f\"  BASE_SIZE: {config_module.BASE_SIZE}\")\n",
    "print(f\"  IMAGE_SIZE: {config_module.IMAGE_SIZE}\")\n",
    "print(f\"  CROP_MODE: {config_module.CROP_MODE}\")\n",
    "print(f\"  NUM_WORKERS: {config_module.NUM_WORKERS}\")\n",
    "\n",
    "def process_single_figure(fig_path):\n",
    "    \"\"\"Apply DeepSeek preprocessing to a single figure\"\"\"\n",
    "    try:\n",
    "        # Load figure\n",
    "        figure = Image.open(fig_path)\n",
    "        \n",
    "        # Apply DeepSeek preprocessing\n",
    "        processed = processor_pass2.tokenize_with_images(\n",
    "            images=[figure], \n",
    "            bos=True, \n",
    "            eos=True, \n",
    "            cropping=config_module.CROP_MODE\n",
    "        )\n",
    "        \n",
    "        return (fig_path.name, True, processed)\n",
    "    except Exception as e:\n",
    "        return (fig_path.name, False, str(e))\n",
    "\n",
    "# Get all figures from temp/figures/ in SORTED order\n",
    "figure_files = sorted(Path(TEMP_FIGURES_DIR).glob(\"*.png\"))\n",
    "total_figures = len(figure_files)\n",
    "\n",
    "if total_figures == 0:\n",
    "    print(\"\\nâš  No figures found in temp/figures/\")\n",
    "    print(\"Run Cell 7 first to extract figures from Pass 1 output\")\n",
    "    batch_inputs_pass2 = []\n",
    "else:\n",
    "    print(f\"\\nFound {total_figures} figures to preprocess\")\n",
    "    print(f\"Using {PASS2_NUM_WORKERS} worker threads\\n\")\n",
    "\n",
    "    preprocess_start = time.time()\n",
    "\n",
    "    # Store results with filenames for later sorting\n",
    "    results = []\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=PASS2_NUM_WORKERS) as executor:\n",
    "        # Submit all jobs\n",
    "        futures = {\n",
    "            executor.submit(process_single_figure, fig_path): fig_path\n",
    "            for fig_path in figure_files\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(futures):\n",
    "            fig_name, success, result = future.result()\n",
    "            \n",
    "            if success:\n",
    "                results.append((fig_name, result))\n",
    "                successful += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "                print(f\"âœ— Failed: {fig_name}: {result}\")\n",
    "            \n",
    "            # Progress indicator\n",
    "            if total_figures > 100 and (successful + failed) % 50 == 0:\n",
    "                print(f\"  Progress: {successful + failed}/{total_figures} figures processed...\")\n",
    "\n",
    "    # CRITICAL: Sort results by filename to maintain order\n",
    "    results.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Build batch_inputs_pass2 in sorted order\n",
    "    batch_inputs_pass2 = []\n",
    "    for fig_name, processed in results:\n",
    "        batch_inputs_pass2.append({\n",
    "            \"prompt\": PASS2_PROMPT,\n",
    "            \"multi_modal_data\": {\"image\": processed},\n",
    "        })\n",
    "\n",
    "    preprocess_time = time.time() - preprocess_start\n",
    "    figures_per_sec = successful / preprocess_time if preprocess_time > 0 else 0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  Total Figures: {total_figures}\")\n",
    "    print(f\"  Successful: {successful}\")\n",
    "    print(f\"  Failed: {failed}\")\n",
    "    print(f\"  Time: {preprocess_time:.2f}s ({figures_per_sec:.2f} figures/sec)\")\n",
    "    print(f\"  Workers: {PASS2_NUM_WORKERS}\")\n",
    "    print(f\"  Batch inputs ready (SORTED): {len(batch_inputs_pass2)}\")\n",
    "    print(f\"âœ“ Pass 2 Preprocessing Complete\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    timing_data['deepseek_preprocessing_pass2'] = preprocess_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888d5d9-14c6-4be5-82bc-bfe847161113",
   "metadata": {},
   "source": [
    "# Cell 8b: Run Pass 2 on GPU - \"Deep Parsing\"\n",
    "- Creates Pass 2 sampling params (higher temp, skip special tokens)\n",
    "- Processes all figures through GPU in batches\n",
    "- Cleans up any grounding artifacts from descriptions\n",
    "- Stores results in figure_descriptions dictionary (filename â†’ description)\n",
    "- Keeps everything in memory ready for stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c0784-33bb-4047-a193-78fdb1c9c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8b: GPU Processing - Pass 2 Deep Parse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU PROCESSING - PASS 2 DEEP PARSE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check that we have preprocessed figures from Cell 8\n",
    "if 'batch_inputs_pass2' not in globals() or len(batch_inputs_pass2) == 0:\n",
    "    print(\"\\nâš  No figures to process (batch_inputs_pass2 is empty)\")\n",
    "    print(\"Skipping Pass 2 - no figure descriptions generated\")\n",
    "    figure_descriptions = {}  # Empty dict for downstream cells\n",
    "    timing_data['gpu_inference_pass2'] = 0.0\n",
    "    print(\"\\nâœ“ Pass 2 skipped\")\n",
    "else:\n",
    "    total_figures = len(batch_inputs_pass2)\n",
    "print(f\"\\nProcessing {total_figures} preprocessed figures\")\n",
    "print(f\"Batch size (max_num_seqs): {PASS2_MAX_NUM_SEQS}\")\n",
    "print(f\"GPU Memory Utilization: {PASS2_GPU_MEMORY_UTIL}\")\n",
    "\n",
    "# Create sampling params for Pass 2\n",
    "from vllm import SamplingParams\n",
    "from process.ngram_norepeat import NoRepeatNGramLogitsProcessor\n",
    "\n",
    "logits_processors_pass2 = [NoRepeatNGramLogitsProcessor(\n",
    "    ngram_size=20, window_size=50, whitelist_token_ids={128821, 128822}\n",
    ")]\n",
    "\n",
    "sampling_params_pass2 = SamplingParams(\n",
    "    temperature=PASS2_TEMPERATURE,\n",
    "    max_tokens=PASS2_MAX_TOKENS,\n",
    "    logits_processors=logits_processors_pass2,\n",
    "    skip_special_tokens=True,  # Skip grounding tokens for cleaner descriptions\n",
    "    include_stop_str_in_output=False,\n",
    ")\n",
    "\n",
    "print(f\"Temperature: {PASS2_TEMPERATURE}\")\n",
    "print(f\"Max tokens: {PASS2_MAX_TOKENS}\")\n",
    "\n",
    "# Run GPU inference\n",
    "gpu_start = time.time()\n",
    "\n",
    "outputs_pass2 = llm.generate(batch_inputs_pass2, sampling_params=sampling_params_pass2)\n",
    "\n",
    "gpu_time = time.time() - gpu_start\n",
    "figures_per_sec = total_figures / gpu_time if gpu_time > 0 else 0\n",
    "\n",
    "print(f\"\\nâœ“ GPU Processing Complete\")\n",
    "print(f\"  Time: {gpu_time:.2f}s ({figures_per_sec:.2f} figures/sec)\")\n",
    "\n",
    "# Process outputs and clean up any remaining artifacts\n",
    "print(f\"\\nCleaning descriptions...\")\n",
    "\n",
    "figure_files = sorted(Path(TEMP_FIGURES_DIR).glob(\"*.png\"))\n",
    "figure_descriptions = {}  # filename -> description\n",
    "\n",
    "for fig_path, output in zip(figure_files, outputs_pass2):\n",
    "    raw_description = output.outputs[0].text\n",
    "    \n",
    "    # Clean any remaining grounding artifacts\n",
    "    description = raw_description\n",
    "    description = re.sub(r'<\\|ref\\|>[^<]*<\\|/ref\\|>', '', description)\n",
    "    description = re.sub(r'<\\|det\\|>[^<]*<\\|/det\\|>', '', description)\n",
    "    description = re.sub(r'<\\|grounding\\|>', '', description)\n",
    "    description = re.sub(r'<center>.*?</center>', '', description, flags=re.DOTALL)\n",
    "    description = re.sub(r'<[^>]+>', '', description)\n",
    "    description = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', description).strip()\n",
    "    \n",
    "    figure_descriptions[fig_path.name] = description\n",
    "\n",
    "print(f\"âœ“ Generated {len(figure_descriptions)} descriptions\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"PASS 2 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  Total Figures: {total_figures}\")\n",
    "print(f\"  GPU Time: {gpu_time:.2f}s\")\n",
    "print(f\"  Throughput: {figures_per_sec:.2f} figures/sec\")\n",
    "print(f\"  Descriptions stored in memory\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['gpu_inference_pass2'] = gpu_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b277fdc-c077-4cf9-b284-c7d78491541f",
   "metadata": {},
   "source": [
    "# Cell 9: Merge Text with Image Descriptions and Save Output\n",
    "- Loads all Pass 1 markdown files in sorted order\n",
    "- For each page, finds matching figure descriptions by filename pattern\n",
    "- Inserts descriptions after their corresponding image tags inline\n",
    "- Adds page numbers and separators\n",
    "- Combines all pages into one complete document\n",
    "- Saves to output/{pdf_name}_complete.md\n",
    "- Handles multiple PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce965382-bbb6-4b40-9fe9-70f975d40fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Stitch Results & Save Final Output (Multi-PDF)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STITCHING RESULTS & SAVING FINAL OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start timing\n",
    "stitching_start = time.time() \n",
    "\n",
    "# Check that we have figure descriptions from Cell 9\n",
    "if 'figure_descriptions' not in globals() or len(figure_descriptions) == 0:\n",
    "    print(\"\\nâš  No figure descriptions found from Pass 2\")\n",
    "    print(\"Proceeding with Pass 1 markdown only (no figure descriptions)\")\n",
    "    figure_descriptions = {}\n",
    "\n",
    "print(f\"\\nFigure descriptions available: {len(figure_descriptions)}\")\n",
    "\n",
    "def insert_figure_descriptions_in_page(markdown_text, page_stem, figure_descriptions):\n",
    "    \"\"\"\n",
    "    Insert figure descriptions after their corresponding image tags in a single page's markdown.\n",
    "    \"\"\"\n",
    "    if not figure_descriptions:\n",
    "        return markdown_text\n",
    "    \n",
    "    # Find all figures that belong to this page\n",
    "    # Format: {page_stem}_fig01.png, {page_stem}_fig02.png, etc.\n",
    "    page_figures = {\n",
    "        fig_name: desc \n",
    "        for fig_name, desc in figure_descriptions.items() \n",
    "        if fig_name.startswith(page_stem + \"_fig\")\n",
    "    }\n",
    "    \n",
    "    if not page_figures:\n",
    "        return markdown_text\n",
    "    \n",
    "    result = markdown_text\n",
    "    \n",
    "    # For each figure on this page\n",
    "    for fig_name, description in sorted(page_figures.items()):\n",
    "        # Extract figure number from filename (e.g., \"document_page0001_fig02.png\" -> fig 2)\n",
    "        fig_match = re.search(r'_fig(\\d+)\\.png$', fig_name)\n",
    "        if not fig_match:\n",
    "            continue\n",
    "        \n",
    "        fig_num = int(fig_match.group(1))\n",
    "        \n",
    "        # Find the nth image tag in the markdown\n",
    "        # Pattern: <|ref|>image<|/ref|><|det|>[[...]]<|/det|>\n",
    "        pattern = r'(<\\|ref\\|>image<\\|/ref\\|><\\|det\\|>\\[\\[.*?\\]\\]<\\|/det\\|>)'\n",
    "        matches = list(re.finditer(pattern, result))\n",
    "        \n",
    "        if fig_num <= len(matches):\n",
    "            # Get the position of this figure's tag\n",
    "            match = matches[fig_num - 1]\n",
    "            tag_end = match.end()\n",
    "            \n",
    "            # Insert description after the tag\n",
    "            description_insert = f'\\n\\n**Figure {fig_num} Description:**\\n{description}\\n'\n",
    "            result = result[:tag_end] + description_insert + result[tag_end:]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Process all markdown files from Pass 1\n",
    "markdown_files = sorted(Path(TEMP_PASS1_RAW_DIR).glob(\"*.md\"))\n",
    "total_pages = len(markdown_files)\n",
    "\n",
    "print(f\"Processing {total_pages} markdown files...\")\n",
    "\n",
    "# Group pages by PDF\n",
    "# Filename format: {pdf_stem}_page{0001}.md\n",
    "pdf_pages = defaultdict(list)  # pdf_stem -> list of (page_num, markdown_path)\n",
    "\n",
    "for md_path in markdown_files:\n",
    "    page_stem = md_path.stem  # e.g., \"document_page0001\"\n",
    "    \n",
    "    # Extract PDF name and page number\n",
    "    match = re.match(r'(.+)_page(\\d+)$', page_stem)\n",
    "    if match:\n",
    "        pdf_stem = match.group(1)\n",
    "        page_num = int(match.group(2))\n",
    "        pdf_pages[pdf_stem].append((page_num, md_path))\n",
    "    else:\n",
    "        print(f\"âš  Couldn't parse filename: {page_stem}\")\n",
    "\n",
    "print(f\"\\nFound {len(pdf_pages)} PDF(s) to process\\n\")\n",
    "\n",
    "# Process each PDF separately\n",
    "output_files = []\n",
    "total_figures_added = 0\n",
    "\n",
    "for pdf_stem, pages in sorted(pdf_pages.items()):\n",
    "    print(f\"Processing: {pdf_stem}\")\n",
    "    \n",
    "    # Sort pages by page number\n",
    "    pages.sort(key=lambda x: x[0])\n",
    "    \n",
    "    final_markdown_pages = []\n",
    "    pages_with_figures = 0\n",
    "    \n",
    "    for page_num, md_path in pages:\n",
    "        page_stem = md_path.stem\n",
    "        \n",
    "        # Read original markdown from Pass 1\n",
    "        with open(md_path, 'r', encoding='utf-8') as f:\n",
    "            page_markdown = f.read()\n",
    "        \n",
    "        # Insert figure descriptions if any exist for this page\n",
    "        enhanced_markdown = insert_figure_descriptions_in_page(\n",
    "            page_markdown, \n",
    "            page_stem, \n",
    "            figure_descriptions\n",
    "        )\n",
    "        \n",
    "        # Check if figures were added\n",
    "        if enhanced_markdown != page_markdown:\n",
    "            pages_with_figures += 1\n",
    "        \n",
    "        # Add page separator and store\n",
    "        page_with_header = f\"\\n{'='*70}\\nPAGE {page_num}\\n{'='*70}\\n\\n{enhanced_markdown}\\n\\n\"\n",
    "        final_markdown_pages.append(page_with_header)\n",
    "    \n",
    "    # Combine all pages into final document for this PDF\n",
    "    final_document = ''.join(final_markdown_pages)\n",
    "    \n",
    "    # Save final markdown\n",
    "    output_filename = f\"{pdf_stem}_complete.md\"\n",
    "    output_path = Path(OUTPUT_DIR) / output_filename\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(final_document)\n",
    "    \n",
    "    output_files.append(output_path)\n",
    "    total_figures_added += pages_with_figures\n",
    "    \n",
    "    print(f\"  âœ“ {len(pages)} pages, {pages_with_figures} with figures\")\n",
    "    print(f\"    Saved: {output_filename} ({output_path.stat().st_size / 1024:.2f} KB)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"  PDFs Processed: {len(pdf_pages)}\")\n",
    "print(f\"  Total Pages: {total_pages}\")\n",
    "print(f\"  Pages with Figures: {total_figures_added}\")\n",
    "print(f\"  Figure Descriptions Added: {len(figure_descriptions)}\")\n",
    "print(f\"\\nâœ“ Output files saved to: {OUTPUT_DIR}\")\n",
    "for output_path in output_files:\n",
    "    print(f\"  - {output_path.name}\")\n",
    "print(f\"âœ“ STITCHING COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['stitching'] = time.time() - stitching_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19fbab-6dee-4c5c-b2f7-aee6a230cf8f",
   "metadata": {},
   "source": [
    "# Cell 10: Post-Processing / Markdown Formatting\n",
    "- Opens each file /workspace/output/\n",
    "- Adds source filename metadata at top\n",
    "- Removes all grounding tags and coordinates\n",
    "- Removes `<center>` tags (keeps the caption text)\n",
    "- Removes image links\n",
    "- Removes special tokens\n",
    "- Cleans up whitespace\n",
    "- Saves cleaned version with same filename (overwrites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ace2a-17eb-42d0-838a-dcb77799b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Clean Markdown Output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CLEANING MARKDOWN OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Start timing\n",
    "cleaning_start = time.time()\n",
    "\n",
    "def clean_markdown(text, source_filename):\n",
    "    \"\"\"\n",
    "    Clean markdown by removing grounding tags, coordinates, and special tokens.\n",
    "    Add source file metadata at the top.\n",
    "    \"\"\"\n",
    "    # Add source file metadata at top\n",
    "    header = f\"<!-- Source: {source_filename} -->\\n\\n\"\n",
    "    text = header + text\n",
    "    \n",
    "    # Remove all grounding tags and their coordinates\n",
    "    # Pattern: <|ref|>content<|/ref|><|det|>[[coordinates]]<|/det|>\n",
    "    text = re.sub(r'<\\|ref\\|>.*?<\\|/ref\\|><\\|det\\|>\\[\\[.*?\\]\\]<\\|/det\\|>', '', text)\n",
    "    \n",
    "    # Remove any standalone grounding tags that might remain\n",
    "    text = re.sub(r'<\\|ref\\|>.*?<\\|/ref\\|>', '', text)\n",
    "    text = re.sub(r'<\\|det\\|>.*?<\\|/det\\|>', '', text)\n",
    "    text = re.sub(r'<\\|box\\|>.*?<\\|/box\\|>', '', text)\n",
    "    \n",
    "    # Remove end-of-sentence tokens\n",
    "    text = re.sub(r'<ï½œendâ–ofâ–sentenceï½œ>', '', text)\n",
    "    \n",
    "    # Remove image links (markdown image syntax)\n",
    "    # Pattern: ![anything](./images/anything)\n",
    "    text = re.sub(r'!\\[.*?\\]\\(\\.\\/images\\/.*?\\)', '', text)\n",
    "    \n",
    "    # Remove <center> tags but keep the text inside\n",
    "    # Pattern: <center>text</center>\n",
    "    text = re.sub(r'<center>(.*?)</center>', r'\\1', text)\n",
    "    \n",
    "    # Clean up excessive blank lines (3+ blank lines â†’ 2 blank lines)\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "    \n",
    "    # Remove trailing whitespace from each line\n",
    "    text = '\\n'.join(line.rstrip() for line in text.split('\\n'))\n",
    "    \n",
    "    # Remove leading/trailing whitespace from entire document\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Ensure file ends with single newline\n",
    "    text = text + '\\n'\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Find all complete markdown files\n",
    "markdown_files = sorted(Path(OUTPUT_DIR).glob(\"*_complete.md\"))\n",
    "total_files = len(markdown_files)\n",
    "\n",
    "if total_files == 0:\n",
    "    print(\"\\nâš  No *_complete.md files found in output directory\")\n",
    "    print(f\"   Looking in: {OUTPUT_DIR}\")\n",
    "    print(\"\\nâœ— Nothing to clean\")\n",
    "else:\n",
    "    print(f\"\\nFound {total_files} markdown file(s) to clean\\n\")\n",
    "    \n",
    "    cleaned_files = []\n",
    "    total_size_before = 0\n",
    "    total_size_after = 0\n",
    "    \n",
    "    for md_path in markdown_files:\n",
    "        # Extract original PDF filename (remove _complete.md suffix)\n",
    "        pdf_filename = md_path.stem.replace('_complete', '') + '.pdf'\n",
    "        \n",
    "        # Read original markdown\n",
    "        with open(md_path, 'r', encoding='utf-8') as f:\n",
    "            original_text = f.read()\n",
    "        \n",
    "        original_size = len(original_text)\n",
    "        total_size_before += original_size\n",
    "        \n",
    "        # Clean the markdown\n",
    "        cleaned_text = clean_markdown(original_text, pdf_filename)\n",
    "        \n",
    "        cleaned_size = len(cleaned_text)\n",
    "        total_size_after += cleaned_size\n",
    "        \n",
    "        # Save cleaned version (overwrite original)\n",
    "        with open(md_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned_text)\n",
    "        \n",
    "        # Calculate reduction\n",
    "        reduction = ((original_size - cleaned_size) / original_size * 100) if original_size > 0 else 0\n",
    "        \n",
    "        cleaned_files.append(md_path)\n",
    "        \n",
    "        print(f\"âœ“ Cleaned: {md_path.name}\")\n",
    "        print(f\"  Before: {original_size / 1024:.2f} KB\")\n",
    "        print(f\"  After:  {cleaned_size / 1024:.2f} KB\")\n",
    "        print(f\"  Reduced: {reduction:.1f}%\\n\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"CLEANING SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  Files Cleaned: {total_files}\")\n",
    "    print(f\"  Total Size Before: {total_size_before / 1024:.2f} KB\")\n",
    "    print(f\"  Total Size After:  {total_size_after / 1024:.2f} KB\")\n",
    "    \n",
    "    total_reduction = ((total_size_before - total_size_after) / total_size_before * 100) if total_size_before > 0 else 0\n",
    "    print(f\"  Total Reduction: {total_reduction:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Clean markdown files saved to: {OUTPUT_DIR}\")\n",
    "    for cleaned_path in cleaned_files:\n",
    "        print(f\"  - {cleaned_path.name}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ CLEANING COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "timing_data['markdown_cleaning'] = time.time() - cleaning_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a80e8a-de3d-4d17-8489-db455a4f50f1",
   "metadata": {},
   "source": [
    "# Cell 11: Performance Metrics & Benchmarking\n",
    "- Calculates total pipeline time starting at Cell 6a and stopping here\n",
    "- Shows detailed timing breakdown with percentages\n",
    "- Calculates throughput metrics (pages/sec, GB/hour, etc.)\n",
    "- Shows extrapolations for larger batches\n",
    "- Summarizes configuration used\n",
    "- Saves comprehensive JSON report to reports/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec999d2-492e-4988-9b6a-4f8be50ebb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Performance Metrics & Benchmarking\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE METRICS & BENCHMARKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate total pipeline time\n",
    "pipeline_end = time.time()\n",
    "total_pipeline_time = pipeline_end - pipeline_start\n",
    "\n",
    "# Get PDF statistics\n",
    "pdf_files = sorted(Path(PDF_INPUT_DIR).glob(\"*.pdf\"))\n",
    "total_pdfs = len(pdf_files)\n",
    "total_size_mb = sum(f.stat().st_size for f in pdf_files) / (1024**2)\n",
    "total_size_gb = total_size_mb / 1024\n",
    "\n",
    "# Get page count from temp/pages\n",
    "page_files = list(Path(TEMP_PAGES_DIR).glob(\"*.png\"))\n",
    "total_pages = len(page_files)\n",
    "\n",
    "# Get figure count from temp/figures\n",
    "figure_files = list(Path(TEMP_FIGURES_DIR).glob(\"*.png\"))\n",
    "total_figures = len(figure_files)\n",
    "\n",
    "# Display timing breakdown\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIMING BREAKDOWN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "timing_labels = {\n",
    "    'pdf_to_images': 'PDF â†’ Page Images (CPU)',\n",
    "    'deepseek_preprocessing_pass1': 'DeepSeek Preprocessing - Pass 1 (CPU)',\n",
    "    'gpu_inference_pass1': 'GPU Inference - Pass 1',\n",
    "    'figure_extraction': 'Figure Extraction & Cropping (CPU)',\n",
    "    'deepseek_preprocessing_pass2': 'DeepSeek Preprocessing - Pass 2 (CPU)',\n",
    "    'gpu_inference_pass2': 'GPU Inference - Pass 2',\n",
    "    'stitching': 'Stitching Results (CPU)'\n",
    "}\n",
    "\n",
    "stage_times = []\n",
    "for key, label in timing_labels.items():\n",
    "    if key in timing_data:\n",
    "        stage_time = timing_data[key]\n",
    "        percentage = (stage_time / total_pipeline_time) * 100 if total_pipeline_time > 0 else 0\n",
    "        print(f\"{label:.<50} {stage_time:>7.2f}s ({percentage:>5.1f}%)\")\n",
    "        stage_times.append(stage_time)\n",
    "    else:\n",
    "        print(f\"{label:.<50} {'SKIPPED':>7}\")\n",
    "\n",
    "# Calculate overhead (time not accounted for in stages)\n",
    "accounted_time = sum(stage_times)\n",
    "overhead = total_pipeline_time - accounted_time\n",
    "overhead_pct = (overhead / total_pipeline_time) * 100 if total_pipeline_time > 0 else 0\n",
    "\n",
    "print(f\"{'Other/Overhead':.<50} {overhead:>7.2f}s ({overhead_pct:>5.1f}%)\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'TOTAL PIPELINE TIME':.<50} {total_pipeline_time:>7.2f}s (100.0%)\")\n",
    "\n",
    "# Throughput metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THROUGHPUT METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nInput:\")\n",
    "print(f\"  PDFs Processed: {total_pdfs}\")\n",
    "print(f\"  Total Pages: {total_pages}\")\n",
    "print(f\"  Total Size: {total_size_mb:.2f} MB ({total_size_gb:.3f} GB)\")\n",
    "print(f\"  Figures Extracted: {total_figures}\")\n",
    "\n",
    "print(f\"\\nSpeed:\")\n",
    "sec_per_page = total_pipeline_time / total_pages if total_pages > 0 else 0\n",
    "pages_per_sec = total_pages / total_pipeline_time if total_pipeline_time > 0 else 0\n",
    "print(f\"  Seconds/Page: {sec_per_page:.2f}\")\n",
    "print(f\"  Pages/Second: {pages_per_sec:.2f}\")\n",
    "\n",
    "if total_figures > 0:\n",
    "    sec_per_figure = timing_data.get('gpu_inference_pass2', 0) / total_figures\n",
    "    print(f\"  Seconds/Figure (Pass 2): {sec_per_figure:.2f}\")\n",
    "\n",
    "print(f\"\\nData Throughput:\")\n",
    "if total_size_gb > 0 and total_pipeline_time > 0:\n",
    "    mb_per_sec = total_size_mb / total_pipeline_time\n",
    "    gb_per_hour = (total_size_gb / total_pipeline_time) * 3600\n",
    "    hours_per_gb = (total_pipeline_time / total_size_gb) / 3600\n",
    "    \n",
    "    print(f\"  MB/second: {mb_per_sec:.2f}\")\n",
    "    print(f\"  GB/hour: {gb_per_hour:.2f}\")\n",
    "    print(f\"  Hours/GB: {hours_per_gb:.2f}\")\n",
    "\n",
    "# Extrapolations\n",
    "print(f\"\\nExtrapolations:\")\n",
    "if total_size_gb > 0:\n",
    "    time_per_gb = total_pipeline_time / total_size_gb\n",
    "    print(f\"  Time for 1 GB: {time_per_gb/60:.2f} minutes\")\n",
    "    print(f\"  Time for 10 GB: {(time_per_gb*10)/60:.2f} minutes ({(time_per_gb*10)/3600:.2f} hours)\")\n",
    "    print(f\"  Time for 100 GB: {(time_per_gb*100)/3600:.2f} hours ({(time_per_gb*100)/86400:.2f} days)\")\n",
    "\n",
    "# Configuration summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nPass 1:\")\n",
    "print(f\"  Resolution: {BASE_SIZE}x{BASE_SIZE}, Image Size: {IMAGE_SIZE}\")\n",
    "print(f\"  Crop Mode: {CROP_MODE}\")\n",
    "print(f\"  Batch Size: {PASS1_MAX_NUM_SEQS}\")\n",
    "print(f\"  Temperature: {PASS1_TEMPERATURE}\")\n",
    "print(f\"  Max Tokens: {PASS1_MAX_TOKENS}\")\n",
    "\n",
    "print(f\"\\nPass 2:\")\n",
    "print(f\"  Resolution: {PASS2_BASE_SIZE}x{PASS2_BASE_SIZE}, Image Size: {PASS2_IMAGE_SIZE}\")\n",
    "print(f\"  Crop Mode: {PASS2_CROP_MODE}\")\n",
    "print(f\"  Batch Size: {PASS2_MAX_NUM_SEQS}\")\n",
    "print(f\"  Temperature: {PASS2_TEMPERATURE}\")\n",
    "print(f\"  Max Tokens: {PASS2_MAX_TOKENS}\")\n",
    "\n",
    "print(f\"\\nCPU:\")\n",
    "print(f\"  Workers (Pass 1): {NUM_WORKERS}\")\n",
    "print(f\"  Workers (Pass 2): {PASS2_NUM_WORKERS}\")\n",
    "\n",
    "print(f\"\\nGPU:\")\n",
    "print(f\"  Model: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"  Memory Utilization: {PASS1_GPU_MEMORY_UTIL}\")\n",
    "\n",
    "# Save detailed JSON report\n",
    "timestamp = int(time.time())\n",
    "report_data = {\n",
    "    \"timestamp\": timestamp,\n",
    "    \"pipeline\": {\n",
    "        \"total_time_seconds\": total_pipeline_time,\n",
    "        \"total_time_minutes\": total_pipeline_time / 60,\n",
    "        \"total_time_hours\": total_pipeline_time / 3600\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"pdfs_processed\": total_pdfs,\n",
    "        \"total_pages\": total_pages,\n",
    "        \"total_figures\": total_figures,\n",
    "        \"total_size_mb\": total_size_mb,\n",
    "        \"total_size_gb\": total_size_gb\n",
    "    },\n",
    "    \"timing_breakdown\": timing_data,\n",
    "    \"throughput\": {\n",
    "        \"seconds_per_page\": sec_per_page,\n",
    "        \"pages_per_second\": pages_per_sec,\n",
    "        \"mb_per_second\": mb_per_sec if total_size_gb > 0 else 0,\n",
    "        \"gb_per_hour\": gb_per_hour if total_size_gb > 0 else 0,\n",
    "        \"hours_per_gb\": hours_per_gb if total_size_gb > 0 else 0\n",
    "    },\n",
    "    \"configuration\": {\n",
    "        \"pass1\": {\n",
    "            \"base_size\": BASE_SIZE,\n",
    "            \"image_size\": IMAGE_SIZE,\n",
    "            \"crop_mode\": CROP_MODE,\n",
    "            \"batch_size\": PASS1_MAX_NUM_SEQS,\n",
    "            \"temperature\": PASS1_TEMPERATURE,\n",
    "            \"max_tokens\": PASS1_MAX_TOKENS,\n",
    "            \"prompt\": PASS1_PROMPT\n",
    "        },\n",
    "        \"pass2\": {\n",
    "            \"base_size\": PASS2_BASE_SIZE,\n",
    "            \"image_size\": PASS2_IMAGE_SIZE,\n",
    "            \"crop_mode\": PASS2_CROP_MODE,\n",
    "            \"batch_size\": PASS2_MAX_NUM_SEQS,\n",
    "            \"temperature\": PASS2_TEMPERATURE,\n",
    "            \"max_tokens\": PASS2_MAX_TOKENS,\n",
    "            \"prompt\": PASS2_PROMPT\n",
    "        },\n",
    "        \"cpu_workers_pass1\": NUM_WORKERS,\n",
    "        \"cpu_workers_pass2\": PASS2_NUM_WORKERS,\n",
    "        \"gpu\": {\n",
    "            \"device\": torch.cuda.get_device_name(0),\n",
    "            \"memory_utilization\": PASS1_GPU_MEMORY_UTIL\n",
    "        }\n",
    "    },\n",
    "    \"pdfs\": [\n",
    "        {\n",
    "            \"filename\": pdf.name,\n",
    "            \"size_mb\": pdf.stat().st_size / (1024**2)\n",
    "        }\n",
    "        for pdf in pdf_files\n",
    "    ]\n",
    "}\n",
    "\n",
    "report_filename = f\"benchmark_report_{timestamp}.json\"\n",
    "report_path = Path(REPORTS_DIR) / report_filename\n",
    "\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report_data, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"âœ“ Benchmark report saved: {report_filename}\")\n",
    "print(f\"  Location: {report_path}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935b805-4105-4603-8ad3-3eb71f9a569a",
   "metadata": {},
   "source": [
    "# Reference - Resolution Settings\n",
    "\n",
    "For Tiny mode:\n",
    "- BASE_SIZE = 512\n",
    "- IMAGE_SIZE = 512\n",
    "- CROP_MODE = False\n",
    "\n",
    "For Small mode:\n",
    "- BASE_SIZE = 640\n",
    "- IMAGE_SIZE = 640\n",
    "- CROP_MODE = False\n",
    "\n",
    "For Base mode:\n",
    "- BASE_SIZE = 1024\n",
    "- IMAGE_SIZE = 1024\n",
    "- CROP_MODE = False\n",
    "\n",
    "For Large mode:\n",
    "- BASE_SIZE = 1280\n",
    "- IMAGE_SIZE = 1280\n",
    "- CROP_MODE = False\n",
    "\n",
    "For Gundam mode (default):\n",
    "- BASE_SIZE = 1024\n",
    "- IMAGE_SIZE = 640\n",
    "- CROP_MODE = True  # This is the key to enabling/disabling Gundam mode!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
